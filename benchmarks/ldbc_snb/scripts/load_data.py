#!/usr/bin/env python3
"""
Load LDBC SNB data into ClickHouse.

This script loads data generated by the LDBC datagen Docker image.
The data uses '|' as delimiter and has a specific directory structure.

Usage:
    python load_data.py --scale-factor sf0.003
    python load_data.py --scale-factor sf0.1 --host localhost --port 9000
"""

import argparse
import glob
import os
import subprocess
from pathlib import Path

# Map from directory name to ClickHouse table name
# The datagen produces directories with CamelCase names
STATIC_TABLES = [
    # Static reference data (order matters for foreign keys)
    ("Place", "static/Place"),
    ("TagClass", "static/TagClass"),
    ("Tag", "static/Tag"),
    ("Organisation", "static/Organisation"),
    # Static relationships
    ("Place_isPartOf_Place", "static/Place_isPartOf_Place"),
    ("Organisation_isLocatedIn_Place", "static/Organisation_isLocatedIn_Place"),
    ("Tag_hasType_TagClass", "static/Tag_hasType_TagClass"),
    ("TagClass_isSubclassOf_TagClass", "static/TagClass_isSubclassOf_TagClass"),
]

DYNAMIC_TABLES = [
    # Dynamic entities
    ("Person", "dynamic/Person"),
    ("Forum", "dynamic/Forum"),
    ("Post", "dynamic/Post"),
    ("Comment", "dynamic/Comment"),
    # Person relationships (datagen names differ slightly)
    ("Person_isLocatedIn_Place", "dynamic/Person_isLocatedIn_City"),  # City -> Place
    ("Person_hasInterest_Tag", "dynamic/Person_hasInterest_Tag"),
    ("Person_studyAt_Organisation", "dynamic/Person_studyAt_University"),  # University -> Organisation  
    ("Person_workAt_Organisation", "dynamic/Person_workAt_Company"),  # Company -> Organisation
    ("Person_knows_Person", "dynamic/Person_knows_Person"),
    ("Person_likes_Post", "dynamic/Person_likes_Post"),
    ("Person_likes_Comment", "dynamic/Person_likes_Comment"),
    # Forum relationships
    ("Forum_hasModerator_Person", "dynamic/Forum_hasModerator_Person"),
    ("Forum_hasMember_Person", "dynamic/Forum_hasMember_Person"),
    ("Forum_hasTag_Tag", "dynamic/Forum_hasTag_Tag"),
    ("Forum_containerOf_Post", "dynamic/Forum_containerOf_Post"),
    # Post relationships (datagen uses Country instead of Place)
    ("Post_hasCreator_Person", "dynamic/Post_hasCreator_Person"),
    ("Post_isLocatedIn_Place", "dynamic/Post_isLocatedIn_Country"),  # Country -> Place
    ("Post_hasTag_Tag", "dynamic/Post_hasTag_Tag"),
    # Comment relationships
    ("Comment_hasCreator_Person", "dynamic/Comment_hasCreator_Person"),
    ("Comment_isLocatedIn_Place", "dynamic/Comment_isLocatedIn_Country"),  # Country -> Place
    ("Comment_hasTag_Tag", "dynamic/Comment_hasTag_Tag"),
    ("Comment_replyOf_Post", "dynamic/Comment_replyOf_Post"),
    ("Comment_replyOf_Comment", "dynamic/Comment_replyOf_Comment"),
]


def find_csv_file(data_dir: Path) -> Path | None:
    """Find the CSV file in an LDBC datagen directory (may have random suffix)."""
    csv_files = list(data_dir.glob("*.csv"))
    if csv_files:
        return csv_files[0]
    return None


def load_table(table_name: str, csv_path: Path, host: str, port: int, database: str, user: str, password: str):
    """Load a pipe-delimited CSV file into a ClickHouse table."""
    if not csv_path.exists():
        print(f"  WARNING: File not found: {csv_path}")
        return False
    
    # LDBC datagen uses '|' as delimiter and epoch-millis timestamps
    # Use clickhouse-client with custom format settings
    query = f"INSERT INTO {table_name} FORMAT CSVWithNames SETTINGS format_csv_delimiter='|'"
    cmd = [
        "clickhouse-client",
        f"--host={host}",
        f"--port={port}",
        f"--user={user}",
        f"--password={password}",
        f"--database={database}",
        f"--query={query}",
    ]
    
    try:
        with open(csv_path, 'rb') as f:
            result = subprocess.run(
                cmd,
                stdin=f,
                capture_output=True,
                text=True
            )
        
        if result.returncode != 0:
            print(f"  ERROR loading {table_name}: {result.stderr}")
            return False
        
        return True
    except Exception as e:
        print(f"  ERROR: {e}")
        return False


def get_row_count(table_name: str, host: str, port: int, database: str, user: str, password: str) -> int:
    """Get row count for a table."""
    cmd = [
        "clickhouse-client",
        f"--host={host}",
        f"--port={port}",
        f"--user={user}",
        f"--password={password}",
        f"--database={database}",
        f"--query=SELECT count() FROM {table_name}",
    ]
    
    try:
        result = subprocess.run(cmd, capture_output=True, text=True)
        if result.returncode == 0:
            return int(result.stdout.strip())
    except:
        pass
    return 0


def main():
    parser = argparse.ArgumentParser(description="Load LDBC SNB data into ClickHouse")
    parser.add_argument("--scale-factor", "-s", default="sf0.003",
                       help="Scale factor (sf0.003, sf0.1, sf1, etc.)")
    parser.add_argument("--host", default="localhost",
                       help="ClickHouse host")
    parser.add_argument("--port", type=int, default=9000,
                       help="ClickHouse native port (default: 9000)")
    parser.add_argument("--database", default="ldbc",
                       help="Database name (default: ldbc)")
    parser.add_argument("--data-dir", default=None,
                       help="Data directory (default: ./data/<scale-factor>)")
    parser.add_argument("--skip-static", action="store_true",
                       help="Skip loading static tables")
    parser.add_argument("--skip-dynamic", action="store_true",
                       help="Skip loading dynamic tables")
    parser.add_argument("--user", "-u", default="default",
                       help="ClickHouse user (default: default)")
    parser.add_argument("--password", "-p", default="default",
                       help="ClickHouse password (default: default)")
    
    args = parser.parse_args()
    
    # Determine data directory - datagen outputs to graphs/csv/interactive/composite-projected-fk/
    script_dir = Path(__file__).parent
    if args.data_dir:
        data_dir = Path(args.data_dir)
    else:
        data_dir = script_dir.parent / "data" / args.scale_factor / "graphs" / "csv" / "interactive" / "composite-projected-fk"
    
    if not data_dir.exists():
        print(f"ERROR: Data directory not found: {data_dir}")
        print(f"Please run: ./scripts/download_data.sh {args.scale_factor}")
        return 1
    
    print("=" * 60)
    print("LDBC SNB Data Loader")
    print("=" * 60)
    print(f"Scale Factor: {args.scale_factor}")
    print(f"Data Directory: {data_dir}")
    print(f"ClickHouse: {args.host}:{args.port}")
    print(f"Database: {args.database}")
    print(f"User: {args.user}")
    print("=" * 60)
    
    tables_to_load = []
    if not args.skip_static:
        tables_to_load.extend(STATIC_TABLES)
    if not args.skip_dynamic:
        tables_to_load.extend(DYNAMIC_TABLES)
    
    success_count = 0
    error_count = 0
    
    for table_name, subdir in tables_to_load:
        # Find the CSV file in the directory (has random suffix)
        dir_path = data_dir / subdir
        csv_path = find_csv_file(dir_path)
        
        if csv_path is None:
            print(f"Loading {table_name}... SKIP (no CSV in {subdir})")
            continue
            
        print(f"Loading {table_name}...", end=" ", flush=True)
        
        if load_table(table_name, csv_path, args.host, args.port, args.database, args.user, args.password):
            count = get_row_count(table_name, args.host, args.port, args.database, args.user, args.password)
            print(f"âœ“ ({count:,} rows)")
            success_count += 1
        else:
            error_count += 1
    
    print("=" * 60)
    print(f"Load complete: {success_count} tables loaded, {error_count} errors")
    print("=" * 60)
    
    return 0 if error_count == 0 else 1


if __name__ == "__main__":
    exit(main())
